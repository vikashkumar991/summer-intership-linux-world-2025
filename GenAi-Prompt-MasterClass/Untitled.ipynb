{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f6885a-166d-4c14-8466-53e4a8504cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'AIzaSyBAMw1JHyBGLBWJHpvPqTyr9ZPFxFF81fM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590d390-556a-4760-9950-9059345e673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df5ea4-ef94-40df-a1c5-7c8df980c18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e98cd-3800-4ab2-8799-e26305d58239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99de3f8-8a96-466c-aa2e-74295da7d6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03d965-b2ed-4a54-b945-7defeaad7ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba1f3e-8606-4eeb-a96f-c940408ff084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b0d95-c03c-4d82-a16a-66828ab986d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee1e2a-b881-43b4-a2c0-df9d26dd4435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4dc0120-9732-40da-a911-284299ee854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378d5eb3-e45e-4609-8625-f88173ade19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = OpenAI(api_key=key, base_url = \"https://generativelanguage.googleapis.com/v1beta/openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44dd0d-36cd-41b7-a071-0b5ea89ec099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1669cc-ae4f-4e9e-9a3e-f213806c3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userMsg(prompt):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a project architect. Respond with a short, clear, high-level plan. \"\n",
    "                \"Limit the response to 4–5 key points only. \"\n",
    "                \"Include tech stack, cost estimate, and 1–2 optimization suggestions.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = gemini_model.chat.completions.create(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee57ce0c-1e1c-4a4e-9463-e83d7aaa73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = userMsg(\"i want to make a project in which we make a device for old people and childs real time update of their body and health to their parents phone and alert system if there is any emergeny and send help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288f33c1-b51a-470f-861a-4603f2eac510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77dd7809-d776-4a09-add0-33a611e97314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\gradio\\utils.py\", line 940, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_26244\\380455251.py\", line 17, in userMsg\n",
      "    response = gemini_model.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'API Key not found. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API Key not found. Please pass a valid API key.'}]}}]\n"
     ]
    }
   ],
   "source": [
    "gd.Interface(fn = userMsg, inputs = \"text\", outputs = \"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d555d7-d3d3-41c8-9e9b-0a8bbe5cfb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
